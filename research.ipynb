{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "f:\\Chatbot\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"I need this report urgently, it's really important!\" -> Importance Score: 5.99\n",
      "Query: \"This response is completely unacceptable. I'm very upset!\" -> Importance Score: 10.0\n",
      "Query: \"Could you send me the file when you get the chance?\" -> Importance Score: 10.0\n",
      "Query: \"This is a critical priority for us.\" -> Importance Score: 5.99\n",
      "Query: \"Nice Job\" -> Importance Score: 6.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize sentiment-analysis pipeline using a pre-trained BERT model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function to calculate importance score based on sentiment analysis\n",
    "def analyze_query_importance(query):\n",
    "    # 1. Sentiment Analysis using BERT\n",
    "    sentiment = sentiment_analyzer(query)[0]\n",
    "    \n",
    "    label = sentiment['label']\n",
    "    score = sentiment['score']\n",
    "\n",
    "    # 2. Calculate the importance score based on sentiment\n",
    "    if label == 'NEGATIVE':\n",
    "        base_score = 7  # Higher base score for negative sentiment (shows dissatisfaction)\n",
    "    elif label == 'POSITIVE':\n",
    "        base_score = 3  # Lower score for positive sentiment\n",
    "    else:\n",
    "        base_score = 5  # Neutral sentiment base score\n",
    "    \n",
    "    # 3. Use the sentiment score confidence to adjust the importance score (e.g., increase for higher confidence)\n",
    "    importance_score = base_score + (score * 3)  # Scale the score\n",
    "    \n",
    "    # Ensure the score stays within bounds (e.g., 0-10)\n",
    "    importance_score = max(0, min(importance_score, 10))\n",
    "\n",
    "    return round(importance_score, 2)\n",
    "\n",
    "# Test the function with different user queries\n",
    "queries = [\n",
    "    \"I need this report urgently, it's really important!\",\n",
    "    \"This response is completely unacceptable. I'm very upset!\",\n",
    "    \"Could you send me the file when you get the chance?\",\n",
    "    \"This is a critical priority for us.\",\n",
    "    'Nice Job'\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    score = analyze_query_importance(query)\n",
    "    print(f\"Query: \\\"{query}\\\" -> Importance Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Chatbot\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"I need this report urgently, it's really important!\" -> Importance Score: 7.63\n",
      "Query: \"This response is completely unacceptable. I'm very upset!\" -> Importance Score: 10\n",
      "Query: \"Could you send me the file when you get the chance?\" -> Importance Score: 7.7\n",
      "Query: \"This is a critical priority for us.\" -> Importance Score: 7.75\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to extract BERT embeddings for a given query\n",
    "def get_bert_embedding(query):\n",
    "    inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # The hidden state of the last layer [batch_size, sequence_length, hidden_size]\n",
    "    # Extract the embedding of the [CLS] token for sentence-level embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    \n",
    "    return cls_embedding\n",
    "\n",
    "# Function to classify sentiment and importance based on BERT embeddings\n",
    "def analyze_query_importance(query, sentiment_reference, importance_reference):\n",
    "    # 1. Get BERT embeddings for the input query\n",
    "    query_embedding = get_bert_embedding(query)\n",
    "    \n",
    "    # 2. Compute similarity with reference sentiment and importance embeddings\n",
    "    sentiment_sim = cosine_similarity([query_embedding], sentiment_reference)\n",
    "    importance_sim = cosine_similarity([query_embedding], importance_reference)\n",
    "    \n",
    "    # 3. Classify sentiment based on similarity scores\n",
    "    sentiment_label = 'POSITIVE' if sentiment_sim[0][1] > sentiment_sim[0][0] else 'NEGATIVE'\n",
    "    sentiment_score = max(sentiment_sim[0])  # Use the max similarity as the score\n",
    "\n",
    "    # 4. Classify importance based on similarity scores\n",
    "    importance_label = 'IMPORTANT' if importance_sim[0][1] > importance_sim[0][0] else 'NOT IMPORTANT'\n",
    "    importance_score = max(importance_sim[0])  # Use the max similarity as the score\n",
    "    \n",
    "    # 5. Calculate final importance score (combining sentiment and importance)\n",
    "    base_score = 7 if sentiment_label == 'NEGATIVE' else 3\n",
    "    if importance_label == 'IMPORTANT':\n",
    "        base_score += 2  # Boost score for important queries\n",
    "    \n",
    "    # Adjust the score based on sentiment/importance confidence\n",
    "    importance_score_final = base_score + (sentiment_score * 3)\n",
    "    importance_score_final = max(0, min(importance_score_final, 10))  # Ensure score is between 0 and 10\n",
    "    \n",
    "    return round(importance_score_final, 2)\n",
    "\n",
    "# Prepare reference embeddings for sentiment and importance classification\n",
    "# These could be example phrases you know are positive/negative, important/not important\n",
    "positive_query = \"I am happy with the results.\"\n",
    "negative_query = \"I am very unhappy with the service.\"\n",
    "important_query = \"This is a critical priority task.\"\n",
    "not_important_query = \"No rush, take your time.\"\n",
    "\n",
    "# Get BERT embeddings for reference queries\n",
    "sentiment_reference = [\n",
    "    get_bert_embedding(negative_query),\n",
    "    get_bert_embedding(positive_query)\n",
    "]\n",
    "\n",
    "importance_reference = [\n",
    "    get_bert_embedding(not_important_query),\n",
    "    get_bert_embedding(important_query)\n",
    "]\n",
    "\n",
    "# Test the function with different user queries\n",
    "queries = [\n",
    "    \"I need this report urgently, it's really important!\",\n",
    "    \"This response is completely unacceptable. I'm very upset!\",\n",
    "    \"Could you send me the file when you get the chance?\",\n",
    "    \"This is a critical priority for us.\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    score = analyze_query_importance(query, sentiment_reference, importance_reference)\n",
    "    print(f\"Query: \\\"{query}\\\" -> Importance Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summarizer\n",
      "  Downloading summarizer-0.0.7.tar.gz (280 kB)\n",
      "     ---------------------------------------- 0.0/280.1 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 20.5/280.1 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 102.4/280.1 kB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 225.3/280.1 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 280.1/280.1 kB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in f:\\chatbot\\venv\\lib\\site-packages (from nltk->summarizer) (1.4.2)\n",
      "Requirement already satisfied: click in f:\\chatbot\\venv\\lib\\site-packages (from nltk->summarizer) (8.1.7)\n",
      "Requirement already satisfied: tqdm in f:\\chatbot\\venv\\lib\\site-packages (from nltk->summarizer) (4.66.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\chatbot\\venv\\lib\\site-packages (from nltk->summarizer) (2024.7.24)\n",
      "Requirement already satisfied: colorama in f:\\chatbot\\venv\\lib\\site-packages (from click->nltk->summarizer) (0.4.6)\n",
      "Installing collected packages: nltk, summarizer\n",
      "  Running setup.py install for summarizer: started\n",
      "  Running setup.py install for summarizer: finished with status 'done'\n",
      "Successfully installed nltk-3.9.1 summarizer-0.0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: summarizer is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Summarizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m Summarizer()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Generate the summary with a minimum length of 60 characters\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m bert_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Print the generated summary\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERT Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Summarizer' object is not callable"
     ]
    }
   ],
   "source": [
    "# Install summarizer if not installed\n",
    "# pip install summarizer transformers\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "# The text you want to summarize\n",
    "body = '''\n",
    "       Scientists say they have discovered a new species of orangutans on Indonesia’s island of Sumatra.\n",
    "       The population differs in several ways from the two existing orangutan species found in Sumatra and the neighboring island of Borneo.\n",
    "       The orangutans were found inside North Sumatra’s Batang Toru forest, the science publication Current Biology reported.\n",
    "       Researchers named the new species the Tapanuli orangutan. They say the animals are considered a new species because of genetic, skeletal and tooth differences.\n",
    "       Michael Kruetzen is a geneticist with the University of Zurich who has studied the orangutans for several years. He said he was excited to be part of the unusual discovery of a new great ape in the present day. He noted that most great apes are currently considered endangered or severely endangered.\n",
    "       Gorillas, chimpanzees and bonobos also belong to the great ape species.\n",
    "       Orangutan – which means person of the forest in the Indonesian and Malay languages - is the world’s biggest tree-living mammal. The orange-haired animals can move easily among the trees because their arms are longer than their legs. They live more lonely lives than other great apes, spending a lot of time sleeping and eating fruit in the forest.\n",
    "       The new study said fewer than 800 of the newly-described orangutans exist. Their low numbers make the group the most endangered of all the great ape species.\n",
    "       They live within an area covering about 1,000 square kilometers. The population is considered highly vulnerable. That is because the environment which they depend on is greatly threatened by development.\n",
    "       Researchers say if steps are not taken quickly to reduce the current and future threats, the new species could become extinct “within our lifetime.”\n",
    "       Research into the new species began in 2013, when an orangutan protection group in Sumatra found an injured orangutan in an area far away from the other species. The adult male orangutan had been beaten by local villagers and died of his injuries. The complete skull was examined by researchers.\n",
    "       Among the physical differences of the new species are a notably smaller head and frizzier hair. The Tapanuli orangutans also have a different diet and are found only in higher forest areas.\n",
    "       There is no unified international system for recognizing new species. But to be considered, discovery claims at least require publication in a major scientific publication.\n",
    "       Russell Mittermeier is head of the primate specialist group at the International Union for the Conservation of Nature. He called the finding a “remarkable discovery.” He said it puts responsibility on the Indonesian government to help the species survive.\n",
    "       Matthew Nowak is one of the writers of the study. He told the Associated Press that there are three groups of the Tapanuli orangutans that are separated by non-protected land. He said forest land needs to connect the separated groups.\n",
    "       In addition, the writers of the study are recommending that plans for a hydropower center in the area be stopped by the government.\n",
    "       It also recommended that remaining forest in the Sumatran area where the orangutans live be protected.\n",
    "       I’m Bryan Lynn.\n",
    "'''\n",
    "\n",
    "# Initialize the BERT summarizer model\n",
    "bert_model = Summarizer()\n",
    "\n",
    "# Generate the summary with a minimum length of 60 characters\n",
    "bert_summary = ''.join(bert_model(body, min_length=60))\n",
    "\n",
    "# Print the generated summary\n",
    "print(\"BERT Summary:\")\n",
    "print(bert_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
